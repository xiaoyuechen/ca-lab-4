Part 1:

  Q1: The hit rate is 0%. The cache block size is 4 bytes, so we could only pull
  the current element we are accessing to the cache. When we access the same
  element after we have iterated over all the 255 other elements, it has already
  been kicked out from the cache by other elements because we only have 512 bytes
  in cache in total, which is only enough for 126 elements.

  Q2: since we miss each cache access see (Q1), we have a total of (number of elements)*(number of itterations)=256*10=2560 cache misses.
  
  Q3: Since we now effecticely double the size of the cache we will be able to store all of the elements in it. This means that at the
  last nine iteration throught the matrix, (since of our "bad loop ordering") we will ONLY have cache hits in the last nine iterations through the matrix. 
  
  Additionally since we load two words in each blocks, we will get misses the first column and store all those elements and the following one in memory,
  but at the second column we will have stored all of the elements in the cache by virtue of the previus columns cache save, this pattern repeats for the third and fourth column.
  So two columns of hits and two of misses. 
  Total miss is (number of rows)(2) = 64 * 2 = 128
  
  Q4: The hit rate does not change. We take the last bit of memory address
  to decide which set of cache the word should go to. When we access the same
  element after we have iterated over all the 255 other elements, it has already
  been kicked out from the cache by the element whose memory address is the memory
  address of the element we are accessing + 8. So the hit rate would still be 0%.

  Q5: Since each block is as large as an element,we only load one element into the 
  cache for each miss so we don't g5et any advantage from data locality within a single matrix iteration. 
  This is true for both cache types.
  The second opportunity to get hits from data locality is after the first iteration through the matrix, 
  but ONLY IF the cache can store the whole matrix. Meaning we need at least 
  a cache size of (size of element)(nr of elements) = 4 * 256 = 1024 bytes

  Q6: Block size of 16 bytes gives the best hit rate 98%. Since we have a cache
  with total size of 1024 bytes, we never evict any elements from the cache.
  Therefore, the more data we could fetch to the cache each time, the better hit
  rate we would have. 16 bytes block would fetch 4 elements at a time. It is the
  best for the hit rate.

  Q7: Since the cache size is big enough for all the elements, we won't have
  cache misses after the first iteration. During the first iteration, we would
  miss 64 times. Total memory access count of the program is 64 * 4 * 10. 
  So the hit rate is 1 - (64/(64*4*10)) = 97.5%.
  
Part 2:

  Q1: The hitrate does not increse (0%), The fundamental problem is similiar to before.
  The block can only hold one element so we won't get any "data locality benefits" from 
  within the loop. Furthermore the size of the matrix is larger than the size of the cache,
  or in other words, there are more elements in the matrix than there are blocks in the cache. 
  This means that the data stored in cache from the first matrix iteration will have been evicted
  before the program needs it at the second iteration etc. computation: 0 hits/2560 accesses = 0%
  





