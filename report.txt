Part 1:

  Q1: The hit rate is 0%. The cache block size is 4 bytes, so we could only pull
  the current element we are accessing to the cache. When we access the same
  element after we have iterated over all the 255 other elements, it has already
  been kicked out from the cache by other elements because we only have 512 bytes
  in cache in total, which is only enough for 126 elements.

  Q2: since we miss each cache access see (Q1), we have a total of (number of elements)*(number of itterations)=256*10=2560 cache misses. 
  Compulsory misses are misses that can't be avoided by a larger cache or from larger associativity sets. 
  Since the block size is the same as the element size, and we at least will get each element into the cache.
  We get a total of one compulsory miss for each element = 256
  
  Q3: 
  Compulsory misses: Here we store two elements in each block and so we only
  "need" (nr of elements) / (elements per block) = (256)/(2) = 128 cache accesses
  to have accessed all of the data at least once. So we will have 128 compulsory misses.
  
  Q4: The hit rate does not change. We take the last bit of memory address
  to decide which set of cache the word should go to. When we access the same
  element after we have iterated over all the 255 other elements, it has already
  been kicked out from the cache by the element whose memory address is the memory
  address of the element we are accessing + 8. So the hit rate would still be 0%.

  Q5: Since each block is as large as an element,we only load one element into the 
  cache for each miss so we don't g5et any advantage from data locality within a single matrix iteration. 
  This is true for both cache types.
  The second opportunity to get hits from data locality is after the first iteration through the matrix, 
  but ONLY IF the cache can store the whole matrix. Meaning we need at least 
  a cache size of (size of element)(nr of elements) = 4 * 256 = 1024 bytes

  Q6: Block size of 16 bytes gives the best hit rate 98%. Since we have a cache
  with total size of 1024 bytes, we never evict any elements from the cache.
  Therefore, the more data we could fetch to the cache each time, the better hit
  rate we would have. 16 bytes block would fetch 4 elements at a time. It is the
  best for the hit rate.

  Q7: Since the cache size is big enough for all the elements, we won't have
  cache misses after the first iteration. During the first iteration, we would
  miss 64 times. Total memory access count of the program is 64 * 4 * 10. 
  So the hit rate is 1 - (64/(64*4*10)) = 97.5%.
  
Part 2:

  Q1: The hitrate does not increse (0%), The fundamental problem is similiar to before.
  The block can only hold one element so we won't get any "data locality benefits" from 
  within the loop. Furthermore the size of the matrix is larger than the size of the cache,
  or in other words, there are more elements in the matrix than there are blocks in the cache. 
  This means that the data stored in cache from the first matrix iteration will have been evicted
  before the program needs it at the second iteration etc. computation: 0 hits/2560 accesses = 0%
  
  Q2: The hit rate improve to 50%. This is because we pull the element and the
  element after it into the 8-byte block every time. Therefore 1/2 = 50%.

  Q3: The hit rate improve to 75%. Similar to Q2, we pull 4 element into the
  cache each time, hence 3/4 = 75% hit rate.

  Q4: We miss all access when pulling during the 1st of the 10 iterations. So
  9/10 = 90% hit rate.

  Q5: We only miss during the 1st of the 10 iterations. During the 1st
  iteration, we miss 50% of the time. So overall we miss 0.5 * 1 / 10 = 5%. 
  Hence hit rate 95%.
  
  Q6: We will miss during the first iteration of the matrix every element in the 
  first column as a whole row "fits" in the block. So a total of (nr of rows) = 
  = 64 misses. miss rate = 64/2560 = 2.5%  --> 97.5% hit rate
  
  
  Q4: The hit rate is the same at a 90%. Since the block size is the same one can
  draw the conclussion that these 10% are purely compulsory misses, same as Q3.
  Why? In 4-way associativity the last two bits determine which set a memory 
  address is "assigned" to, basicaly modulo_4. Here 1/4 of the array (16 words) 
  will be assigned into one set, and the same for the other three quarters.
  This will evenly fill up all four sets, and so no conflict misses will occur.
  Only the 128 compulsory misses are left.
  
